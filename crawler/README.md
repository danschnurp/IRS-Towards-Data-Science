# Simple Crawler
- crawling website: [Towards Data Science](https://towardsdatascience.com/) posts(articles) 
read from sitemap.xml and for each post saving title 
and content in `<p>...</p>` by using simple xpath expressions

- before start:
`pip install -r requirements.txt`
- usage: `python main.py`


- prefetch data from this app on my onedrive: [here](https://onedrive.live.com/?authkey=%21AEi6buOuVgTO4QE&id=8D9B8AAC1B2B5597%2185066&cid=8D9B8AAC1B2B5597)
- extract to "./crawled_data"
- if needed, dataset can be easily extended

- parallelization can be added as well but due to politeness of the crawler is not implemented

